{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoon-Hoon-Tiger/PyTorch-Implementations/blob/main/Inception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbc5cb6-d80b-4dd2-960c-2efb479fb8be",
      "metadata": {
        "id": "4bbc5cb6-d80b-4dd2-960c-2efb479fb8be"
      },
      "source": [
        "# Refernce\n",
        "- https://velog.io/@euisuk-chung/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98-%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98%EB%A1%9C-CNN-%EB%AA%A8%EB%8D%B8%EC%9D%84-%EA%B5%AC%ED%98%84%ED%95%B4%EB%B3%B4%EC%9E%90-GoogleNet%ED%8E%B8\n",
        "- https://deep-learning-study.tistory.com/537"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d1359e4-5cd0-440c-bcdd-2b257d1a23c6",
      "metadata": {
        "id": "2d1359e4-5cd0-440c-bcdd-2b257d1a23c6"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8d985b-6b79-419e-8522-d10494b46537",
      "metadata": {
        "id": "ab8d985b-6b79-419e-8522-d10494b46537"
      },
      "source": [
        "# Define Convolution Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b83beda-b7e3-429d-8285-e2c72dcf7d33",
      "metadata": {
        "id": "9b83beda-b7e3-429d-8285-e2c72dcf7d33"
      },
      "source": [
        "## 1 x 1 Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06fcc706-e3b4-4c08-82ea-56259c186b80",
      "metadata": {
        "id": "06fcc706-e3b4-4c08-82ea-56259c186b80"
      },
      "outputs": [],
      "source": [
        "def Conv_1(in_channels, out_channels):\n",
        "    conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 1, 1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return conv1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0385995-cd4a-4265-afb0-329bd10a92a5",
      "metadata": {
        "id": "d0385995-cd4a-4265-afb0-329bd10a92a5"
      },
      "source": [
        "## 1 x 1 Convolution -> 3 x 3 Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbee48c5-1cd4-4da1-abf8-e2a955972afc",
      "metadata": {
        "id": "fbee48c5-1cd4-4da1-abf8-e2a955972afc"
      },
      "outputs": [],
      "source": [
        "def Conv1_3(in_channels, mid_channels, out_channels):\n",
        "    conv1_3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, 1, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(mid_channels, out_channels, 3, 1, 1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return conv1_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f97abe17-d04c-4e35-8a09-78eaac31bffa",
      "metadata": {
        "id": "f97abe17-d04c-4e35-8a09-78eaac31bffa"
      },
      "source": [
        "## 1 x 1 Convolution -> 5 x 5 Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec23ed76-de63-4a46-9f3d-d251a70236e2",
      "metadata": {
        "id": "ec23ed76-de63-4a46-9f3d-d251a70236e2"
      },
      "outputs": [],
      "source": [
        "def Conv1_5(in_channels, mid_channels, out_channels):\n",
        "    conv1_5 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, mid_channels, 1, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(mid_channels, out_channels, 5, 1, 2),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return conv1_5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1ea3749-8c80-43fb-b391-2d4dbf5541ea",
      "metadata": {
        "id": "f1ea3749-8c80-43fb-b391-2d4dbf5541ea"
      },
      "source": [
        "## 3 x 3 Maxpooling -> 1 x 1 Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "692a8344-7283-4689-aa90-63eef42419df",
      "metadata": {
        "id": "692a8344-7283-4689-aa90-63eef42419df"
      },
      "outputs": [],
      "source": [
        "def Max3_Conv1(in_channels, out_channels):\n",
        "    max3_conv1 = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        nn.Conv2d(in_channels, out_channels, 1, 1),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    return max3_conv1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53a382ce-fb4d-44f6-aa37-25fae256e9d4",
      "metadata": {
        "id": "53a382ce-fb4d-44f6-aa37-25fae256e9d4"
      },
      "source": [
        "# Define inception Module\n",
        "- 앞에서 정의한 Conv Block들을 이용하여 concat해주는 단계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b6e3f7-f661-4335-97ef-7b701df5c277",
      "metadata": {
        "id": "63b6e3f7-f661-4335-97ef-7b701df5c277"
      },
      "outputs": [],
      "source": [
        "class inception_module(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels_1, mid_channels_3, out_channels_3, mid_channels_5, out_channels_5, pool_channels):\n",
        "        super(inception_module, self).__init__()\n",
        "        \n",
        "        # 1*1 conv\n",
        "        self.conv_1 = Conv_1(in_channels, out_channels_1)\n",
        "        \n",
        "        # 1*1 conv -> 3*3 conv\n",
        "        self.conv1_3 = Conv1_3(in_channels, mid_channels_3, out_channels_3)\n",
        "        \n",
        "        # 1*1 conv -> 5*5 conv\n",
        "        self.conv1_5 = Conv1_5(in_channels, mid_channels_5, out_channels_5)\n",
        "        \n",
        "        # 3*3 Max -> 1*1 conv\n",
        "        self.max3_1= Max3_Conv1(in_channels, pool_channels)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out_1 = self.conv_1(x)\n",
        "        out_2 = self.conv1_3(x)\n",
        "        out_3 = self.conv1_5(x)\n",
        "        out_4 = self.max3_1(x)\n",
        "        \n",
        "        #concatenation\n",
        "        output = torch.cat([out_1, out_2, out_3, out_4], 1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0fffd09-74cd-4cfd-ab2f-4f76e16eb0a6",
      "metadata": {
        "id": "d0fffd09-74cd-4cfd-ab2f-4f76e16eb0a6"
      },
      "outputs": [],
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        \n",
        "        self.training = True\n",
        "        \n",
        "        self.layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 7, 2, 3),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "            nn.LocalResponseNorm(2),\n",
        "            nn.Conv2d(64, 64, 1),\n",
        "            nn.Conv2d(64, 192, 3, 1, 1),\n",
        "            nn.LocalResponseNorm(2),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        \n",
        "        self.inception_3a = inception_module(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception_3b = inception_module(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool_3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)   \n",
        "            \n",
        "    \n",
        "        self.inception_4a = inception_module(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.aux1 = AuxModule(512, num_classes)\n",
        "        \n",
        "        self.inception_4b = inception_module(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception_4c = inception_module(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception_4d = inception_module(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.aux2 = AuxModule(528, num_classes)\n",
        "        \n",
        "        self.inception_4e = inception_module(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool_4 =nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        \n",
        "        self.inception_5a = inception_module(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception_5b = inception_module(832, 384, 192, 384, 48, 128, 128)\n",
        "        \n",
        "        self.avgpool = nn.AvgPool2d(7, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.layer_1(x)\n",
        "        \n",
        "        out = self.inception_3a(out)\n",
        "        out = self.inception_3b(out)\n",
        "        out = self.maxpool_3(out)\n",
        "        \n",
        "        out = self.inception_4a(out)\n",
        "        if self.training:\n",
        "            aux_out1 = self.aux1(out)\n",
        "            \n",
        "        out = self.inception_4b(out)\n",
        "        out = self.inception_4c(out)\n",
        "        out = self.inception_4d(out)\n",
        "        if self.training:\n",
        "            aux_out2 = self.aux2(out)\n",
        "        \n",
        "        out = self.inception_4e(out)\n",
        "        out = self.maxpool_4(out)\n",
        "        \n",
        "        out = self.inception_5a(out)\n",
        "        out = self.inception_5b(out)\n",
        "        \n",
        "        out = self.avgpool(out)\n",
        "        \n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "        if self.training:\n",
        "            return [out, aux_out1, aux_out2]\n",
        "        else:\n",
        "            return out\n",
        "        \n",
        "    def set_train(self):\n",
        "        self.training = True\n",
        "\n",
        "    def set_eval(self):\n",
        "        self.training = False\n",
        "        \n",
        "class AuxModule(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(AuxModule, self).__init__()\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((4,4))\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 128, kernel_size=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4*4*128, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.7),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = self.conv1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc1252a3-e413-4ab5-a022-67bdb73f6db9",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc1252a3-e413-4ab5-a022-67bdb73f6db9",
        "outputId": "0599d40b-b3d5-4302-da61-c099dfc02478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "torch.Size([3, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ],
      "source": [
        "#네트워크 생성\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "batch_size = 3\n",
        "model = GoogLeNet(3, 10).to(device)\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "print(output[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be974e86-d033-4cd5-9240-c598e9a26d46",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be974e86-d033-4cd5-9240-c598e9a26d46",
        "outputId": "ae69edb6-a85e-41b5-ccd1-104ac61a25f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
            "              ReLU-2         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-3           [-1, 64, 56, 56]               0\n",
            " LocalResponseNorm-4           [-1, 64, 56, 56]               0\n",
            "            Conv2d-5           [-1, 64, 56, 56]           4,160\n",
            "            Conv2d-6          [-1, 192, 56, 56]         110,784\n",
            " LocalResponseNorm-7          [-1, 192, 56, 56]               0\n",
            "         MaxPool2d-8          [-1, 192, 28, 28]               0\n",
            "            Conv2d-9           [-1, 64, 28, 28]          12,352\n",
            "             ReLU-10           [-1, 64, 28, 28]               0\n",
            "           Conv2d-11           [-1, 96, 28, 28]          18,528\n",
            "             ReLU-12           [-1, 96, 28, 28]               0\n",
            "           Conv2d-13          [-1, 128, 28, 28]         110,720\n",
            "             ReLU-14          [-1, 128, 28, 28]               0\n",
            "           Conv2d-15           [-1, 16, 28, 28]           3,088\n",
            "             ReLU-16           [-1, 16, 28, 28]               0\n",
            "           Conv2d-17           [-1, 32, 28, 28]          12,832\n",
            "             ReLU-18           [-1, 32, 28, 28]               0\n",
            "        MaxPool2d-19          [-1, 192, 28, 28]               0\n",
            "           Conv2d-20           [-1, 32, 28, 28]           6,176\n",
            "             ReLU-21           [-1, 32, 28, 28]               0\n",
            " inception_module-22          [-1, 256, 28, 28]               0\n",
            "           Conv2d-23          [-1, 128, 28, 28]          32,896\n",
            "             ReLU-24          [-1, 128, 28, 28]               0\n",
            "           Conv2d-25          [-1, 128, 28, 28]          32,896\n",
            "             ReLU-26          [-1, 128, 28, 28]               0\n",
            "           Conv2d-27          [-1, 192, 28, 28]         221,376\n",
            "             ReLU-28          [-1, 192, 28, 28]               0\n",
            "           Conv2d-29           [-1, 32, 28, 28]           8,224\n",
            "             ReLU-30           [-1, 32, 28, 28]               0\n",
            "           Conv2d-31           [-1, 96, 28, 28]          76,896\n",
            "             ReLU-32           [-1, 96, 28, 28]               0\n",
            "        MaxPool2d-33          [-1, 256, 28, 28]               0\n",
            "           Conv2d-34           [-1, 64, 28, 28]          16,448\n",
            "             ReLU-35           [-1, 64, 28, 28]               0\n",
            " inception_module-36          [-1, 480, 28, 28]               0\n",
            "        MaxPool2d-37          [-1, 480, 14, 14]               0\n",
            "           Conv2d-38          [-1, 192, 14, 14]          92,352\n",
            "             ReLU-39          [-1, 192, 14, 14]               0\n",
            "           Conv2d-40           [-1, 96, 14, 14]          46,176\n",
            "             ReLU-41           [-1, 96, 14, 14]               0\n",
            "           Conv2d-42          [-1, 208, 14, 14]         179,920\n",
            "             ReLU-43          [-1, 208, 14, 14]               0\n",
            "           Conv2d-44           [-1, 16, 14, 14]           7,696\n",
            "             ReLU-45           [-1, 16, 14, 14]               0\n",
            "           Conv2d-46           [-1, 48, 14, 14]          19,248\n",
            "             ReLU-47           [-1, 48, 14, 14]               0\n",
            "        MaxPool2d-48          [-1, 480, 14, 14]               0\n",
            "           Conv2d-49           [-1, 64, 14, 14]          30,784\n",
            "             ReLU-50           [-1, 64, 14, 14]               0\n",
            " inception_module-51          [-1, 512, 14, 14]               0\n",
            "AdaptiveAvgPool2d-52            [-1, 512, 4, 4]               0\n",
            "           Conv2d-53            [-1, 128, 4, 4]          65,664\n",
            "             ReLU-54            [-1, 128, 4, 4]               0\n",
            "           Linear-55                 [-1, 1024]       2,098,176\n",
            "             ReLU-56                 [-1, 1024]               0\n",
            "        Dropout2d-57                 [-1, 1024]               0\n",
            "           Linear-58                   [-1, 10]          10,250\n",
            "        AuxModule-59                   [-1, 10]               0\n",
            "           Conv2d-60          [-1, 160, 14, 14]          82,080\n",
            "             ReLU-61          [-1, 160, 14, 14]               0\n",
            "           Conv2d-62          [-1, 112, 14, 14]          57,456\n",
            "             ReLU-63          [-1, 112, 14, 14]               0\n",
            "           Conv2d-64          [-1, 224, 14, 14]         226,016\n",
            "             ReLU-65          [-1, 224, 14, 14]               0\n",
            "           Conv2d-66           [-1, 24, 14, 14]          12,312\n",
            "             ReLU-67           [-1, 24, 14, 14]               0\n",
            "           Conv2d-68           [-1, 64, 14, 14]          38,464\n",
            "             ReLU-69           [-1, 64, 14, 14]               0\n",
            "        MaxPool2d-70          [-1, 512, 14, 14]               0\n",
            "           Conv2d-71           [-1, 64, 14, 14]          32,832\n",
            "             ReLU-72           [-1, 64, 14, 14]               0\n",
            " inception_module-73          [-1, 512, 14, 14]               0\n",
            "           Conv2d-74          [-1, 128, 14, 14]          65,664\n",
            "             ReLU-75          [-1, 128, 14, 14]               0\n",
            "           Conv2d-76          [-1, 128, 14, 14]          65,664\n",
            "             ReLU-77          [-1, 128, 14, 14]               0\n",
            "           Conv2d-78          [-1, 256, 14, 14]         295,168\n",
            "             ReLU-79          [-1, 256, 14, 14]               0\n",
            "           Conv2d-80           [-1, 24, 14, 14]          12,312\n",
            "             ReLU-81           [-1, 24, 14, 14]               0\n",
            "           Conv2d-82           [-1, 64, 14, 14]          38,464\n",
            "             ReLU-83           [-1, 64, 14, 14]               0\n",
            "        MaxPool2d-84          [-1, 512, 14, 14]               0\n",
            "           Conv2d-85           [-1, 64, 14, 14]          32,832\n",
            "             ReLU-86           [-1, 64, 14, 14]               0\n",
            " inception_module-87          [-1, 512, 14, 14]               0\n",
            "           Conv2d-88          [-1, 112, 14, 14]          57,456\n",
            "             ReLU-89          [-1, 112, 14, 14]               0\n",
            "           Conv2d-90          [-1, 144, 14, 14]          73,872\n",
            "             ReLU-91          [-1, 144, 14, 14]               0\n",
            "           Conv2d-92          [-1, 288, 14, 14]         373,536\n",
            "             ReLU-93          [-1, 288, 14, 14]               0\n",
            "           Conv2d-94           [-1, 32, 14, 14]          16,416\n",
            "             ReLU-95           [-1, 32, 14, 14]               0\n",
            "           Conv2d-96           [-1, 64, 14, 14]          51,264\n",
            "             ReLU-97           [-1, 64, 14, 14]               0\n",
            "        MaxPool2d-98          [-1, 512, 14, 14]               0\n",
            "           Conv2d-99           [-1, 64, 14, 14]          32,832\n",
            "            ReLU-100           [-1, 64, 14, 14]               0\n",
            "inception_module-101          [-1, 528, 14, 14]               0\n",
            "AdaptiveAvgPool2d-102            [-1, 528, 4, 4]               0\n",
            "          Conv2d-103            [-1, 128, 4, 4]          67,712\n",
            "            ReLU-104            [-1, 128, 4, 4]               0\n",
            "          Linear-105                 [-1, 1024]       2,098,176\n",
            "            ReLU-106                 [-1, 1024]               0\n",
            "       Dropout2d-107                 [-1, 1024]               0\n",
            "          Linear-108                   [-1, 10]          10,250\n",
            "       AuxModule-109                   [-1, 10]               0\n",
            "          Conv2d-110          [-1, 256, 14, 14]         135,424\n",
            "            ReLU-111          [-1, 256, 14, 14]               0\n",
            "          Conv2d-112          [-1, 160, 14, 14]          84,640\n",
            "            ReLU-113          [-1, 160, 14, 14]               0\n",
            "          Conv2d-114          [-1, 320, 14, 14]         461,120\n",
            "            ReLU-115          [-1, 320, 14, 14]               0\n",
            "          Conv2d-116           [-1, 32, 14, 14]          16,928\n",
            "            ReLU-117           [-1, 32, 14, 14]               0\n",
            "          Conv2d-118          [-1, 128, 14, 14]         102,528\n",
            "            ReLU-119          [-1, 128, 14, 14]               0\n",
            "       MaxPool2d-120          [-1, 528, 14, 14]               0\n",
            "          Conv2d-121          [-1, 128, 14, 14]          67,712\n",
            "            ReLU-122          [-1, 128, 14, 14]               0\n",
            "inception_module-123          [-1, 832, 14, 14]               0\n",
            "       MaxPool2d-124            [-1, 832, 7, 7]               0\n",
            "          Conv2d-125            [-1, 256, 7, 7]         213,248\n",
            "            ReLU-126            [-1, 256, 7, 7]               0\n",
            "          Conv2d-127            [-1, 160, 7, 7]         133,280\n",
            "            ReLU-128            [-1, 160, 7, 7]               0\n",
            "          Conv2d-129            [-1, 320, 7, 7]         461,120\n",
            "            ReLU-130            [-1, 320, 7, 7]               0\n",
            "          Conv2d-131             [-1, 32, 7, 7]          26,656\n",
            "            ReLU-132             [-1, 32, 7, 7]               0\n",
            "          Conv2d-133            [-1, 128, 7, 7]         102,528\n",
            "            ReLU-134            [-1, 128, 7, 7]               0\n",
            "       MaxPool2d-135            [-1, 832, 7, 7]               0\n",
            "          Conv2d-136            [-1, 128, 7, 7]         106,624\n",
            "            ReLU-137            [-1, 128, 7, 7]               0\n",
            "inception_module-138            [-1, 832, 7, 7]               0\n",
            "          Conv2d-139            [-1, 384, 7, 7]         319,872\n",
            "            ReLU-140            [-1, 384, 7, 7]               0\n",
            "          Conv2d-141            [-1, 192, 7, 7]         159,936\n",
            "            ReLU-142            [-1, 192, 7, 7]               0\n",
            "          Conv2d-143            [-1, 384, 7, 7]         663,936\n",
            "            ReLU-144            [-1, 384, 7, 7]               0\n",
            "          Conv2d-145             [-1, 48, 7, 7]          39,984\n",
            "            ReLU-146             [-1, 48, 7, 7]               0\n",
            "          Conv2d-147            [-1, 128, 7, 7]         153,728\n",
            "            ReLU-148            [-1, 128, 7, 7]               0\n",
            "       MaxPool2d-149            [-1, 832, 7, 7]               0\n",
            "          Conv2d-150            [-1, 128, 7, 7]         106,624\n",
            "            ReLU-151            [-1, 128, 7, 7]               0\n",
            "inception_module-152           [-1, 1024, 7, 7]               0\n",
            "       AvgPool2d-153           [-1, 1024, 1, 1]               0\n",
            "       Dropout2d-154                 [-1, 1024]               0\n",
            "          Linear-155                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,334,030\n",
            "Trainable params: 10,334,030\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 69.72\n",
            "Params size (MB): 39.42\n",
            "Estimated Total Size (MB): 109.72\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, 224, 224), device=device.type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350c8aa0-5d6d-4b47-9e18-bf72c8b08fc6",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "350c8aa0-5d6d-4b47-9e18-bf72c8b08fc6",
        "outputId": "93a2b856-9675-4935-82b3-1b86b9752f26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (layer_1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (3): LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)\n",
              "    (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (5): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): LocalResponseNorm(2, alpha=0.0001, beta=0.75, k=1.0)\n",
              "    (7): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (inception_3a): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_3b): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (maxpool_3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (inception_4a): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (aux1): AuxModule(\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
              "    (conv1): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.7, inplace=False)\n",
              "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_4b): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_4c): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_4d): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (aux2): AuxModule(\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(4, 4))\n",
              "    (conv1): Sequential(\n",
              "      (0): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout2d(p=0.7, inplace=False)\n",
              "      (3): Linear(in_features=1024, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_4e): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (maxpool_4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (inception_5a): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (inception_5b): inception_module(\n",
              "    (conv_1): Sequential(\n",
              "      (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_3): Sequential(\n",
              "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (conv1_5): Sequential(\n",
              "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): ReLU()\n",
              "      (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "    (max3_1): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "  (dropout): Dropout2d(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ce4c3f-2c88-4c87-8556-cac9f3429e6b",
      "metadata": {
        "id": "f6ce4c3f-2c88-4c87-8556-cac9f3429e6b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}